{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFt+xGAh9sfjpyU3CThVzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erikaduda/dsto-gan/blob/main/Pr%C3%A9_processamento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Módulo de Pré-Processamento de Dados\n",
        "\n",
        "Este módulo do programa é responsável pelo **pré-processamento de dados**, uma etapa essencial para preparar conjuntos de dados brutos para análise ou modelagem em tarefas de aprendizado de máquina. O pré-processamento inclui a leitura, limpeza e transformação dos dados, garantindo que estejam em um formato adequado para uso em algoritmos de machine learning. A seguir, descrevemos as funcionalidades principais deste módulo:\n",
        "\n",
        "#### 1. Leitura e Separação dos Atributos e Classe\n",
        "O módulo começa lendo um arquivo de dados, que pode estar em formato CSV ou outro formato tabular. Em seguida, ele separa os **atributos** (features) da **classe** (target). Essa separação é fundamental, pois os atributos são as variáveis independentes usadas para prever a classe, que é a variável dependente ou alvo.\n",
        "\n",
        "#### 2. Codificação de Atributos Nominais\n",
        "Se os atributos forem **nominais** (categóricos não ordenados), o módulo aplica a técnica de **codificação one-hot**. Essa técnica transforma cada categoria nominal em um vetor binário, onde apenas um bit é \"1\" (ativo) e os demais são \"0\". Por exemplo, se um atributo \"Cor\" tiver as categorias \"Vermelho\", \"Verde\" e \"Azul\", a codificação one-hot criará três novas colunas binárias, uma para cada cor. Essa abordagem é necessária porque a maioria dos algoritmos de machine learning não consegue trabalhar diretamente com dados categóricos.\n",
        "\n",
        "#### 3. Codificação da Classe Nominal\n",
        "Se a classe for nominal, o módulo substitui cada item da classe por **números sequenciais**, começando por 0. Por exemplo, se a classe for \"Tipo\" com categorias \"A\", \"B\" e \"C\", ela será transformada em 0, 1 e 2, respectivamente. Essa codificação é comum em problemas de classificação, onde a classe precisa ser representada numericamente.\n",
        "\n",
        "#### 4. Tratamento de Valores Vazios ou Nulos\n",
        "O módulo verifica a presença de valores **vazios** ou **nulos** nos atributos. Se forem encontrados, ele substitui esses valores pela **média** dos valores existentes na respectiva coluna. Essa abordagem é amplamente utilizada para lidar com dados faltantes, garantindo que o conjunto de dados permaneça completo e adequado para análise. A média é calculada apenas para atributos numéricos, enquanto para atributos categóricos, pode-se utilizar a moda (valor mais frequente).\n",
        "\n",
        "#### 5. Gravação do Resultado em Arquivo CSV\n",
        "Após o pré-processamento, o módulo grava o conjunto de dados transformado em um novo arquivo **.csv**. Esse arquivo contém os dados limpos, codificados e prontos para uso em etapas subsequentes, como treinamento de modelos de machine learning. A gravação em formato CSV garante compatibilidade com a maioria das ferramentas e bibliotecas de análise de dados.\n",
        "\n",
        "### Exemplo de Funcionamento\n",
        "Suponha um arquivo de entrada com os seguintes dados:\n",
        "\n",
        "| Idade | Cor    | Salário | Classe |\n",
        "|-------|--------|---------|--------|\n",
        "| 25    | Vermelho | 50000   | A      |\n",
        "| 30    | Verde  |         | B      |\n",
        "| 35    | Azul   | 70000   | A      |\n",
        "\n",
        "Após o pré-processamento, o arquivo de saída seria:\n",
        "\n",
        "| Idade | Cor_Vermelho | Cor_Verde | Cor_Azul | Salário | Classe |\n",
        "|-------|--------------|-----------|----------|---------|--------|\n",
        "| 25    | 1            | 0         | 0        | 50000   | 0      |\n",
        "| 30    | 0            | 1         | 0        | 60000   | 1      |\n",
        "| 35    | 0            | 0         | 1        | 70000   | 0      |\n",
        "\n",
        "Neste exemplo:\n",
        "- O atributo \"Cor\" foi codificado usando one-hot.\n",
        "- O valor faltante em \"Salário\" foi substituído pela média (60000).\n",
        "- A classe \"Classe\" foi codificada numericamente (A = 0, B = 1).\n",
        "\n",
        "### Conclusão\n",
        "Este módulo de pré-processamento é uma ferramenta essencial para garantir a qualidade e a consistência dos dados antes de sua utilização em modelos de machine learning. Ele automatiza tarefas como codificação de atributos categóricos, tratamento de valores faltantes e gravação de dados processados, economizando tempo e reduzindo erros manuais. Ao padronizar o pré-processamento, o módulo contribui para a criação de pipelines de dados mais robustos e eficientes, facilitando a aplicação de técnicas avançadas de análise e modelagem."
      ],
      "metadata": {
        "id": "CGCYtL9fgGst"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0dXKtQ7gAs3",
        "outputId": "0ce421a0-8792-40b6-88b6-40468d7fd73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import sklearn\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "from google.colab import files\n",
        "from pandas import DataFrame\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Função para aplicar codificação one-hot em atributos nominais\n",
        "def apply_one_hot_encoding(data, column):\n",
        "    encoded_data = pd.get_dummies(data[column], prefix=column)\n",
        "    data = pd.concat([data, encoded_data], axis=1)\n",
        "    data.drop(column, axis=1, inplace=True)\n",
        "    return data\n",
        "\n",
        "# Função para substituir atributos vazios pela média\n",
        "def replace_missing_values(data):\n",
        "    data.replace(\"?\", np.nan, inplace=True)  # Substituir \"?\" por NaN\n",
        "    imputer = SimpleImputer(strategy=\"mean\")\n",
        "    data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "    return data_imputed\n",
        "\n",
        "PATH = (\"/content/drive/MyDrive/PHD_new/dataset/falta/\")\n",
        "\n",
        "csv_files = glob.glob(os.path.join(PATH, \"*.csv\"))\n",
        "print(csv_files)\n",
        "print(type(csv_files))\n",
        "\n",
        "for path, dirs, files in os.walk(PATH):\n",
        "    dirs = sorted(dirs)\n",
        "    files = sorted(files)\n",
        "    break\n",
        "\n",
        "for i in range(len(files)):\n",
        "    print(\">>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "    print(\"COUNT FILE: \", i)\n",
        "    print(\"NAME FILE:\", files[i])\n",
        "\n",
        "    # Leitura do arquivo\n",
        "    try:\n",
        "        data = pd.read_csv(PATH + files[i])\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error parsing file {files[i]}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "    # Separar os atributos da classe\n",
        "    class_column = 'class'\n",
        "    class_data = data[class_column]\n",
        "    feature_data = data.drop(class_column, axis=1)\n",
        "\n",
        "    # Verificar se os atributos são nominais e aplicar codificação one-hot se necessário\n",
        "    for column in feature_data.columns:\n",
        "        if feature_data[column].dtype == object:\n",
        "            feature_data = apply_one_hot_encoding(feature_data, column)\n",
        "\n",
        "    # Substituir valores \"?\" por média dos valores\n",
        "    feature_data = replace_missing_values(feature_data)\n",
        "\n",
        "    # Substituir classe nominal por números sequenciais ou valores binários (True=1, False=0)\n",
        "    if class_data.dtype == bool:\n",
        "        class_data = class_data.astype(int)  # Converte bool para int (0 e 1)\n",
        "    elif class_data.dtype == object:\n",
        "        class_data = class_data.map({'True': 1, 'False': 0})  # Mapeia 'True' para 1 e 'False' para 0\n",
        "\n",
        "    # Substituir numerica por números sequenciais\n",
        "    if class_data.dtype == int:\n",
        "        sorted_values = sorted(class_data)\n",
        "        if all(sorted_values[i] == sorted_values[0] + i for i in range(len(sorted_values))):  # Verifica se os valores são sequenciais\n",
        "            class_data = class_data - sorted_values[0]  # Subtrai o primeiro valor para começar de 0\n",
        "        else:\n",
        "            label_encoder = LabelEncoder()\n",
        "            class_data = label_encoder.fit_transform(class_data)\n",
        "\n",
        "\n",
        "   # Substituir classe nominal por números sequenciais ou valores binários (True=1, False=0)\n",
        "    if class_data.dtype == bool:\n",
        "        class_data = class_data.astype(int)  # Converte bool para int (0 e 1)\n",
        "    elif class_data.dtype == object:\n",
        "        class_data = class_data.map({'True': 1, 'False': 0})  # Mapeia 'True' para 1 e 'False' para 0\n",
        "\n",
        "    # Reunir atributos e classe novamente\n",
        "    data_encoded = pd.concat([feature_data, pd.Series(class_data, name=class_column)], axis=1)\n",
        "\n",
        "    # Gravar o resultado em um arquivo CSV\n",
        "    data_encoded.to_csv('/content/drive/MyDrive/PHD_new/dataset_tratado/error/' + files[i], index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxRAnQnpgdwK",
        "outputId": "8b643b1a-c6c5-486c-bc36-b88213403fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/PHD_new/dataset/falta/bank-additional-full.csv']\n",
            "<class 'list'>\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "COUNT FILE:  0\n",
            "NAME FILE: bank-additional-full.csv\n"
          ]
        }
      ]
    }
  ]
}